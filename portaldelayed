import cv2
import numpy as np
from ultralytics import YOLO
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import os, requests, math
from collections import deque

# --- 1. SETUP ---
body_model = YOLO('yolov8n-pose.pt')

download_path = 'hand_landmarker.task'
if not os.path.exists(download_path):
    url = "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
    r = requests.get(url, allow_redirects=True)
    with open(download_path, 'wb') as f: f.write(r.content)

hand_detector = vision.HandLandmarker.create_from_options(vision.HandLandmarkerOptions(
    base_options=python.BaseOptions(model_asset_path=download_path), num_hands=2))

BODY_LINKS = [(5,6), (5,7), (7,9), (6,8), (8,10), (5,11), (6,12), (11,12), (11,13), (13,15), (12,14), (14,16)]

cap = cv2.VideoCapture(0)
fps = 30
# UPDATED: Buffer is now only 1 second long
buffer_size = fps * 1 
frame_buffer = deque(maxlen=buffer_size)

canvas = None
prev_points = {} 
active_portal_mask = None 
hover_mask = None 

while cap.isOpened():
    success, frame = cap.read()
    if not success: break
    
    frame = cv2.flip(frame, 1)
    h, w, _ = frame.shape
    frame_buffer.append(frame.copy())
    
    if canvas is None: canvas = np.zeros((h, w), dtype=np.uint8) 
    hologram = np.zeros((h, w, 3), dtype=np.uint8) 
    display_frame = frame.copy()
    hover_mask = np.zeros((h, w), dtype=np.uint8)

    # --- 2. 1-SECOND TIME RIFT ---
    if active_portal_mask is not None and len(frame_buffer) == buffer_size:
        old_frame = frame_buffer[0] # The frame from 1 second ago
        portal_part = cv2.bitwise_and(old_frame, old_frame, mask=active_portal_mask)
        bg_part = cv2.bitwise_and(display_frame, display_frame, mask=cv2.bitwise_not(active_portal_mask))
        display_frame = cv2.add(portal_part, bg_part)

    # --- 3. AI TRACKING ---
    body_res = body_model(frame, stream=True, verbose=False, conf=0.2, imgsz=320)
    for r_body in body_res:
        if r_body.keypoints is not None:
            for i in range(len(r_body.keypoints.xy)):
                kpts, conf = r_body.keypoints.xy[i].cpu().numpy(), r_body.keypoints.conf[i].cpu().numpy()
                for s, e in BODY_LINKS:
                    if conf[s] > 0.2 and conf[e] > 0.2:
                        cv2.line(hologram, (int(kpts[s][0]), int(kpts[s][1])), (int(kpts[e][0]), int(kpts[e][1])), (0, 255, 0), 2)

    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    hand_res = hand_detector.detect(mp_image)

    finger_pos = None
    if hand_res.hand_landmarks:
        for hand_idx, landmarks in enumerate(hand_res.hand_landmarks):
            pts = [(int(lm.x * w), int(lm.y * h)) for lm in landmarks]
            idx_tip, thumb_tip = pts[8], pts[4]
            finger_pos = idx_tip 

            if math.dist(idx_tip, thumb_tip) < 30:
                if hand_idx in prev_points:
                    cv2.line(canvas, prev_points[hand_idx], idx_tip, 255, 6)
                prev_points[hand_idx] = idx_tip
            else:
                prev_points.pop(hand_idx, None)

    # --- 4. AUTO-DETECT CLOSED SHAPES ---
    contours, _ = cv2.findContours(canvas, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    selected_contour = None
    if finger_pos is not None:
        for cnt in contours:
            dist = cv2.pointPolygonTest(cnt, (float(finger_pos[0]), float(finger_pos[1])), False)
            if dist >= 0:
                selected_contour = cnt
                cv2.drawContours(hover_mask, [cnt], -1, 255, -1)
                break

    # Apply Tint to Hover
    tint_layer = np.zeros_like(display_frame)
    tint_layer[:] = (0, 255, 0) 
    tint_colored = cv2.bitwise_and(tint_layer, tint_layer, mask=hover_mask)
    display_frame = cv2.addWeighted(display_frame, 1, tint_colored, 0.4, 0)

    # --- 5. CONTROLS ---
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'): break
    if key == ord('c'): 
        canvas = np.zeros((h, w), dtype=np.uint8)
        active_portal_mask = None
    if key == ord('p') and selected_contour is not None:
        active_portal_mask = np.zeros((h, w), dtype=np.uint8)
        cv2.drawContours(active_portal_mask, [selected_contour], -1, 255, -1)

    # Visualizing the drawing line
    canvas_3ch = cv2.merge([np.zeros_like(canvas), canvas, np.zeros_like(canvas)])
    final_view = cv2.addWeighted(display_frame, 1, canvas_3ch, 1, 0)
    
    cv2.imshow('1-Sec Time Rift', np.hstack((final_view, hologram)))

cap.release()
cv2.destroyAllWindows()
